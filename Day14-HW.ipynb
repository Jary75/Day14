{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6ce44393-3036-4c90-904f-1e85718f57fb",
   "metadata": {},
   "source": [
    "## Introduction to Data Science\n",
    "\n",
    "#### University of Redlands - DATA 101\n",
    "#### Prof: Joanna Bieri [joanna_bieri@redlands.edu](mailto:joanna_bieri@redlands.edu)\n",
    "#### [Class Website: data101.joannabieri.com](https://joannabieri.com/data101.html)\n",
    "\n",
    "---------------------------------------\n",
    "# Homework Day 14\n",
    "---------------------------------------\n",
    "\n",
    "GOALS:\n",
    "\n",
    "1. Reflect on Algorithmic bias\n",
    "2. Consider your role in Data Ethics\n",
    "3. Report on your reading.\n",
    "\n",
    "----------------------------------------------------------\n",
    "\n",
    "This homework has **3 questions** and **1 reading report**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0c422e3-32b1-452f-89a8-2586784d3957",
   "metadata": {},
   "source": [
    "## Important Information\n",
    "\n",
    "- Email: [joanna_bieri@redlands.edu](mailto:joanna_bieri@redlands.edu)\n",
    "- Office Hours: Duke 209 <a href=\"https://joannabieri.com/schedule.html\"> Click Here for Joanna's Schedule</a>\n",
    "\n",
    "## Day 14 Assignment - same drill.\n",
    "\n",
    "1. Make sure you can **Fork** and **Clone** the Day14 repo from [Redlands-DATA101](https://github.com/Redlands-DATA101)\n",
    "2. Open the file Day14-HW.ipynb and start doing the problems.\n",
    "    * You can do these problems as you follow along with the lecture notes and video.\n",
    "3. Get as far as you can before class.\n",
    "4. Submit what you have so far **Commit** and **Push** to Git.\n",
    "5. Take the daily check in quiz on **Canvas**.\n",
    "7. Come to class with lots of questions!\n",
    "\n",
    "## If you start having trouble with git!!!\n",
    "\n",
    "Some people have reported that GIT is disappearing or giving errors on when they try to use it in Jupyter Lab. Here is another option for interacting with git:\n",
    "\n",
    "[Git Desktop](https://github.com/apps/desktop)\n",
    "\n",
    "If yous start having errors, try downloading this app. I can show you how to use it in class."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15fd0fc5-0e82-4265-a328-e906366c4907",
   "metadata": {},
   "source": [
    "## Report on your Data Ethics reading:\n",
    "\n",
    "**Your answers should be written as neatly as possible in Markdown cells**\n",
    "\n",
    "Your homework for today is all essay and written work. Make sure you respond to the three questions in the lecture:\n",
    "\n",
    "\n",
    "**Reading Report**\n",
    "\n",
    "Write a report about what you learned from your ethics reading exploration. For each book/article you read:\n",
    "\n",
    "1. Include a full proper reference to the book/article.\n",
    "   * BOOK: Author last name, First name. Book Title: Subtitle. Edition, Publisher, Year.\n",
    "   * ONLINE ARTICLE: Author last name, First name. Article Title. Website name, date accessed. html link.\n",
    "   * [MLA styles for citing other types of online work](https://style.mla.org/works-cited/citations-by-format/online-works/?gad_source=1)\n",
    "2. Write a summary in your own words what the book/article was about. Imagine telling your classmates about what they would learn by reading the article.\n",
    "3. Discuss your own reaction to the book/article. Did it have any effect on how you think about data and ethics? Do you agree with the author? What specific ideas really stood out to you?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf53176f-7926-4d4e-967c-5b5bbd011abe",
   "metadata": {},
   "source": [
    "#### Q1 What is your response to our discussion of bias in algorithms? Talk about the pluses and minuses of using algorithms to make decisions in our human world."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4d695d0-8cbd-4e7d-a005-f5468a261451",
   "metadata": {},
   "source": [
    "Using algorithms to make decisions can be really useful, they are fast, consistent and can handle a lot of data at once. For example, they can help clinicians detect patterns in medical data or make recommendations about websites. But there are also risks. Algorithms can pick up biases from the data they have been trained on, which means they can make unfair decisions without us even realizing it. Nor can they replace the empathy and understanding that humans bring to difficult decisions. Moreover, if we trust them too much, we might stop questioning their decisions, even when they are wrong. So, while algorithms can be a great tool, we must use them with care and make sure they do not replace the human, reflective side of decision making.aking."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a527f22-684c-4aee-aa4d-afd435a9c996",
   "metadata": {},
   "source": [
    "#### Q2 How do you train yourself to make the right decisions (or reduce the likelihood of accidentally making the wrong decisions) at those points?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7335bfa0-82c0-46d7-9734-f4300dedfa54",
   "metadata": {},
   "source": [
    "To make better decisions and avoid mistakes, it's important to take our time and gather all the informatian before jumping in. Listening to others and considering different viewpoints can he toou see things more clearly. It’s also really helpful to look back on past decisiom . Trusourur instincts, but also make surofre thinking things through logically. Sometimes asking yourself, \"What would I tell a friend to do?\" can help you make sense of thinge."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccb53850-aa63-44c7-aa05-0251d992e01f",
   "metadata": {},
   "source": [
    "#### Q3 How do you respond when you see bias in someones work? How could you take action to educate others?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "421ce8bc-ea4b-4d27-856a-df0647df7f0d",
   "metadata": {},
   "source": [
    "If I spot bias in someone's work, I'd try to approach it with understanding rather than jumping to criticism. I’d ask questions like, \"Have you thought about this perspective?\" to open up a conversation without making them defensive. To educate others, I’d share examples or resources that show how bias can impact decisions, and encourage people to think critically about their assumptions. I’d also emphasize how having diverse viewpoints helps catch biases and leads to better outcomes. Ultimately, it’s about creating a space where everyone feels comfortable learning and improving together.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ca89bb8-e1ea-4af6-aea6-faf8874deaf2",
   "metadata": {},
   "source": [
    "### Reading report"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5042ef27-5bde-4390-935d-dbdfd5297a60",
   "metadata": {},
   "source": [
    "Author: Joy Buolamwini"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70012810-7378-41d6-8ef2-12a973e969f0",
   "metadata": {},
   "source": [
    "#### Unmasking AI- My mission to protect what is human in a world of machines"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a974f95-bed9-4d9b-aae9-31ba32ef6650",
   "metadata": {},
   "source": [
    "In the first pages of *Unmasking AI*, Joy Buolamwini shares her personal experience with facial recognition technology, revealing her inability to accurately identify her face due to system biases. This situation causes her to begin an investigation into the problem of AI bias, where she discovers that many AI systems are trained on data that has a bias towards lighter-skinned male faces. Buolamwini highlights how this bias can have detrimental consequences in the real world, such as discrimination in areas like in law, hiring etc. She also stresses that AI is often mistakenly perceived as neutral or objective, when in fact it is shaped by the biases of its creators. Part of the reading talks about how AI can perpetuate social inequalities if it is not developed with transparency, fairness and accountability.\n",
    "I never really thought about that kind of problems until we started with our data ethics readings, before that I thought I was generalizing everything and that there were no such problems with face recognition, but after getting more into the world of data ethics I realize all the different issues that it involves. For example at the beginning when I heard “Data Ethics” I thought more about how students should not use GPT chat for their homework and do their own work, but now that I am more informed about it, I understand that it is much more than that, and I also understood that algorithms can be good and bad, before I already knew about algorithms because I was aware of them, for example, all the adds that appear in different social networks, and in fact, I only thought it was like markerting by the companies to promote, or things like that, but now I understand that it is not, and I feel a relief now that I understand the bad things that it can cause and how the world of bias is dangerous and not everybody is aware of that."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6faae4b-ce39-4695-a87f-99e40bda1322",
   "metadata": {},
   "source": [
    "\n",
    "-------------------------------------------------------\n",
    "\n",
    "## Further watching\n",
    "\n",
    "If you have time, really explore the world of data ethics. You could watch some of the videos linked from class.\n",
    "\n",
    "### Weapons of Math Destruction | Cathy O'Neil | Talks at Google\n",
    "\n",
    "{{< video https://www.youtube.com/watch?v=TQHs8SA1qpk >}}\n",
    "\n",
    "### Imagining a Future Free from the Algorithms of Oppression | Safiya Noble | ACL 2019\n",
    "\n",
    "{{< video https://www.youtube.com/watch?v=tNi_U1Bb1S0 >}}\n",
    "\n",
    "### Whats An Algorithm Got To Do With It\n",
    "\n",
    "{{< video https://www.youtube.com/watch?v=5zxDwA99soA >}}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d75adfae-6e62-4549-9856-bf7030620521",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
